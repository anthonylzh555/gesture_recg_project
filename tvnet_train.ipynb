{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets as slimNet\n",
    "from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "from tensorflow.python import _pywrap_tensorflow_internal\n",
    "\n",
    "\n",
    "import mobilenet_v2\n",
    "from tvnet.tvnet import TVNet\n",
    "from file_loader import get_images_from_absdir, img_gen_from_dir, load_txt_from_path\n",
    "from callbacks import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### urfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get urfd directories\n",
    "#\n",
    "daily_path = '/home/jovyan/datasets/elder-fall/UR Fall Detection Dataset(URFD)/UR_Fall_Daily'\n",
    "fall_path = '/home/jovyan/datasets/elder-fall/UR Fall Detection Dataset(URFD)/UR Fall Detection Dataset'\n",
    "\n",
    "urfd_daily = os.listdir(daily_path)\n",
    "urfd_daily.remove('.DS_Store')\n",
    "urfd_daily.sort(key=lambda x: int(x))\n",
    "\n",
    "urfd_fall = os.listdir(fall_path)\n",
    "urfd_fall.remove('.DS_Store')\n",
    "urfd_fall.sort(key=lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get daily data directories\n",
    "#\n",
    "urfd_daily_data_dir = np.asarray([glob.glob(os.path.join(daily_path, i)+'/*rgb*') for i in urfd_daily])\n",
    "urfd_daily_data_dir = np.squeeze(urfd_daily_data_dir)\n",
    "\n",
    "#\n",
    "#Get fall data directories\n",
    "#\n",
    "urfd_fall_data_dir = np.asarray([glob.glob(os.path.join(fall_path, i)+'/*rgb*') for i in urfd_fall])\n",
    "urfd_fall_data_dir = np.squeeze(urfd_fall_data_dir)\n",
    "#Sort the directories in fall data directories(cam0, cam1)\n",
    "for dirs in urfd_fall_data_dir:\n",
    "    dirs.sort()\n",
    "#reshape urfd_fall_data_dir to one dimension\n",
    "urfd_fall_data_dir = urfd_fall_data_dir.reshape(60,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get label files directories\n",
    "#\n",
    "label_path = glob.glob('../../at073-elderfall/collection/archive/DATA/urfd_label/*')\n",
    "label_path = np.asarray(label_path * 2) #there are cam0, and cam1 in urfd fall dataset\n",
    "label_path.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Create dataframe for image data path and label data path\n",
    "#\n",
    "tmp = np.concatenate([urfd_fall_data_dir.reshape(-1, 1), label_path.reshape(-1,1)], axis=1)\n",
    "df_fall = pd.DataFrame(data = tmp, columns=['img_folder', 'label_path'])\n",
    "\n",
    "df_no_fall = pd.DataFrame(data = urfd_daily_data_dir.reshape(-1,1), columns=['img_folder'])\n",
    "df_no_fall['label_path'] = 'None'\n",
    "\n",
    "df_urfd = pd.concat([df_fall, df_no_fall], axis=0).reset_index(drop=True)\n",
    "df_urfd_shuffle = df_urfd.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multicam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get multicam directories\n",
    "#\n",
    "multicam_fall = '../../at073-elderfall/dataset/Multicam/Fall'\n",
    "multicam_non_fall = '../../at073-elderfall/dataset/Multicam/Non_Fall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get multicam fall data directories\n",
    "#\n",
    "m_fall_data_dir = np.asarray(glob.glob(multicam_fall + '/*'))\n",
    "m_fall_data_dir.sort()\n",
    "\n",
    "#\n",
    "#Get multicam non_fall data directories\n",
    "#\n",
    "m_non_fall_data_dir = np.asarray(glob.glob(multicam_non_fall + '/*'))\n",
    "m_non_fall_data_dir.sort()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Create dataframe\n",
    "#\n",
    "df_multiFall = pd.DataFrame(data = m_fall_data_dir.reshape(-1,1), columns=['img_folder'])\n",
    "df_multiNonFall = pd.DataFrame(data = m_non_fall_data_dir.reshape(-1,1), columns=['img_folder'])\n",
    "df_multi = pd.concat([df_multiFall, df_multiNonFall], axis=0).reset_index(drop=True)\n",
    "df_multi['label_path'] = 'None'\n",
    "df_multi_shuffle = df_multi.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get FDD directories\n",
    "#\n",
    "fdd_fall = '../../at073-elderfall/dataset/FDD/Fall'\n",
    "fdd_non_fall = '../../at073-elderfall/dataset/FDD/NoFall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Get FDD fall data directories\n",
    "#\n",
    "fdd_fall_data_dir = np.asarray(glob.glob(fdd_fall+'/*'))\n",
    "fdd_fall_data_dir.sort()\n",
    "\n",
    "#\n",
    "#Get FDD non_fall data directories\n",
    "#\n",
    "fdd_non_fall_data_dir = np.asarray(glob.glob(fdd_non_fall+'/*'))\n",
    "fdd_non_fall_data_dir.sort()\n",
    "\n",
    "###remove the those have less than 11 frames###\n",
    "frame_len = []\n",
    "for imgdir in fdd_fall_data_dir:\n",
    "    frame_len.append(len(glob.glob(imgdir+'/*')))\n",
    "frame_len = np.asarray(frame_len)\n",
    "remove_list = frame_len.argsort()[:5]\n",
    "\n",
    "fdd_fall_data_dir = np.delete(fdd_fall_data_dir, remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Create dataframe\n",
    "#\n",
    "df_fddFall = pd.DataFrame(data = fdd_fall_data_dir.reshape(-1,1), columns=['img_folder'])\n",
    "df_fddNonFall = pd.DataFrame(data = fdd_non_fall_data_dir.reshape(-1,1), columns=['img_folder'])\n",
    "df_fdd = pd.concat([df_fddFall, df_fddNonFall], axis=0).reset_index(drop=True)\n",
    "df_fdd['label_path'] = 'None'\n",
    "df_fdd_shuffle = df_fdd.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fall_imgPath(folder_dir, label_dir):\n",
    "    image_path_list, _ = get_images_from_absdir(folder_dir)\n",
    "    label_list = load_txt_from_path(label_dir)\n",
    "    img_list = image_path_list[int(label_list[0]):int(label_list[1])]\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs_labels(path_list, is_resize, resize_shape):\n",
    "    frame_list = []\n",
    "    \n",
    "    if 'fall-' in path_list[0]:\n",
    "        img_list = get_fall_imgPath(path_list[0], path_list[1])\n",
    "        img_list = np.asarray(img_list)\n",
    "        labels = np.zeros(img_list.shape[0]).reshape(-1,1)\n",
    "    else:\n",
    "        img_list, _ = get_images_from_absdir(path_list[0])\n",
    "        img_list = np.asarray(img_list)\n",
    "        labels = np.ones(img_list.shape[0]).reshape(-1,1)\n",
    "    img_list.sort()  \n",
    "     \n",
    "\n",
    "    for idx, img in enumerate(img_list):\n",
    "        frame = cv2.imread(img)\n",
    "        if is_resize:\n",
    "            frame = cv2.resize(frame, resize_shape, interpolation=cv2.INTER_CUBIC)\n",
    "        frame_list.append(frame)\n",
    "        \n",
    "    return np.asarray(frame_list), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Generator to generate stacks of frames\n",
    "#\n",
    "\n",
    "def imgs_labels_gen(path_df, is_resize, resize_shape):\n",
    "    '''\n",
    "    Images and labels generator.\n",
    "    Input:\n",
    "    * path_df: dataframe with images paths and labels paths as columns\n",
    "    * is_resize: boolean, whether to resize the generated images\n",
    "    * resize_shape: resizing shape\n",
    "    '''\n",
    "    while True:\n",
    "        idx = random.randint(0, len(path_df))\n",
    "        imgs, labels = get_imgs_labels(path_df.iloc[idx].values, is_resize, resize_shape)\n",
    "        yield imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_frames_gen(imgs, labels, L, displacement, stacks):\n",
    "    for s in range(stacks):\n",
    "        img1 = imgs[s*displacement:s*displacement+L-1]\n",
    "        img2 = imgs[s*displacement+1:s*displacement+L]\n",
    "        yield img1, img2\n",
    "    \n",
    "#     img1 = imgs[0:len(imgs)-1]\n",
    "#     img2 = imgs[1:len(imgs)]\n",
    "#     return img1, img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Graph part\n",
    "#\n",
    "\n",
    "main_graph = tf.Graph()\n",
    "with main_graph.as_default():\n",
    "    ###placeholder###\n",
    "    with tf.name_scope('input'):\n",
    "        img1 = tf.placeholder(dtype=tf.float32,\n",
    "                              shape=[None, 224, 224, 3],\n",
    "                              name='img1')\n",
    "        img2 = tf.placeholder(dtype=tf.float32,\n",
    "                              shape=[None, 224, 224, 3],\n",
    "                              name='img2')\n",
    "        lr = tf.placeholder(dtype=tf.float32,\n",
    "                            shape=None,\n",
    "                            name='learning_rate')\n",
    "    ###tvnet###\n",
    "    with tf.variable_scope('tvnet'):\n",
    "        tvnet = TVNet()\n",
    "        tvnet_loss, u1, u2 = tvnet.get_loss(x1=img1, x2=img2)\n",
    "                \n",
    "    ###loss###\n",
    "    with tf.name_scope('loss'):\n",
    "        total_loss = tvnet_loss\n",
    "        \n",
    "    ###train###\n",
    "    with tf.name_scope('train_op'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        grad_var_pairs = optimizer.compute_gradients(total_loss)\n",
    "        update = optimizer.apply_gradients(grad_var_pairs)\n",
    "            \n",
    "    ###others###\n",
    "    var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    all_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model_name' : 'pre_train_tvnet',\n",
    "    'reduce_lr' : ReduceLROnPlateau(lr=1e-3, factor=0.5, patience=5),\n",
    "    'earlystop' : EarlyStopping(min_delta = 1e-4, patience= 10),\n",
    "    'checkpoint' : Model_checkpoint(os.path.join('./pre_train_model_2', 'pre_train_tvnet')),\n",
    "    'train_batch_log' : History(['loss']),\n",
    "    'val_batch_log' : History(['loss']),\n",
    "    'history' : {\n",
    "        'train_loss':[],\n",
    "        'val_loss':[]\n",
    "    },\n",
    "    'testing' : {\n",
    "        'y_true' : [],\n",
    "        'y_pred' : [],\n",
    "        'files'   : []\n",
    "    }\n",
    "}\n",
    "\n",
    "callback_dict = {\n",
    "    'on_session_begin':[], # start of a session\n",
    "    'on_batch_begin':[], # start of a training batch\n",
    "    'on_batch_end':[], # end of a training batch\n",
    "    'on_epoch_begin':[], # start of a epoch\n",
    "    'on_epoch_end':[\n",
    "        model_dict['reduce_lr'],\n",
    "        model_dict['checkpoint']\n",
    "    ], # end of a epoch\n",
    "    'on_session_end':[] # end of a session\n",
    "}\n",
    "callback_manager = Run_collected_functions(callback_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "L = 11\n",
    "displacement = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35db85cb298e4b8ab19f42a01ed8f204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of generating: 0.6011962890625\n",
      "Time of training a video: 148.98572993278503\n",
      "Loss: 0.5728211402893066\n",
      "Time of training a video: 0.7807698249816895\n",
      "Loss: 0.6178855299949646\n",
      "Time of training a video: 0.7798223495483398\n",
      "Loss: 0.665643572807312\n"
     ]
    }
   ],
   "source": [
    "# load_var_list = [v for v in var_list if 'MobilenetV2' in v.name][3:]\n",
    "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True), allow_soft_placement=True, log_device_placement=True)\n",
    "with tf.Session(graph=main_graph, config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    for epoch in tqdm.tqdm_notebook(range(epochs)):\n",
    "        if epoch % 100 == 0:\n",
    "                train_gen = imgs_labels_gen(path_df=df_shuffle, is_resize=True, resize_shape=(224,224))\n",
    "        tmp_loss = 0\n",
    "        X_batch, y_batch = next(train_gen)\n",
    "        stacks = (len(X_batch) - L) // displacement\n",
    "        img_gen = split_frames_gen(imgs=X_batch, L=L, displacement=displacement, stacks=stacks)\n",
    "        for s in range(stacks):\n",
    "            imgs_1, imgs_2 = next(img_gen)\n",
    "            start_time = time.time()\n",
    "            _, loss_value = sess.run([update, total_loss], feed_dict={img1: imgs_1, img2: imgs_2, lr: model_dict['reduce_lr'].lr})\n",
    "            print('Time of training a video: {}'.format(time.time() - start_time))\n",
    "            print('Loss: {}'.format(loss_value))\n",
    "            tmp_loss += loss_value\n",
    "        # Save loss\n",
    "        model_dict['history']['train_loss'].append(tmp_loss/stacks)\n",
    "        # call back\n",
    "        callback_manager.run_on_epoch_end(val_loss=model_dict['history']['train_loss'][-1],\n",
    "                                          sess = sess,\n",
    "                                          saver = saver,\n",
    "                                          nth_epoch = epoch)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
