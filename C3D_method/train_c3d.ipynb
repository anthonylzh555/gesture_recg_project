{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "import c3d_model\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict_values' and 'dict_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a863ab3f1a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a863ab3f1a2a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a863ab3f1a2a>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mvarlist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mvarlist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvarlist2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 logit = c3d_model.inference_c3d(\n\u001b[1;32m    139\u001b[0m                         \u001b[0mimages_placeholder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpu_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict_values' and 'dict_values'"
     ]
    }
   ],
   "source": [
    "# Basic model parameters as external flags.\n",
    "flags = tf.app.flags\n",
    "gpu_num = 2\n",
    "\n",
    "#flags.DEFINE_float('learning_rate', 0.0, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('max_steps', 5000, 'Number of steps to run trainer.')\n",
    "flags.DEFINE_integer('batch_size', 10, 'Batch size.')\n",
    "FLAGS = flags.FLAGS\n",
    "MOVING_AVERAGE_DECAY = 0.9999\n",
    "model_save_dir = './models'\n",
    "\n",
    "\"\"\"\n",
    "Generate placeholder variables to represent the input tensors.\n",
    "These placeholders are used as inputs by the rest of the model building\n",
    "code and will be fed from the downloaded data in the .run() loop, below.\n",
    "Args:\n",
    "batch_size: The batch size will be baked into both placeholders.\n",
    "Returns:\n",
    "images_placeholder: Images placeholder.\n",
    "labels_placeholder: Labels placeholder.\n",
    "\"\"\"\n",
    "\n",
    "def placeholder_inputs(batch_size):\n",
    "# Note that the shapes of the placeholders match the shapes of the full\n",
    "# image and label tensors, except the first dimension is now batch_size\n",
    "# rather than the full size of the train or test data sets.\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(batch_size,\n",
    "                                                         c3d_model.NUM_FRAMES_PER_CLIP,\n",
    "                                                         c3d_model.CROP_SIZE,\n",
    "                                                         c3d_model.CROP_SIZE,\n",
    "                                                         c3d_model.CHANNELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int64, shape=(batch_size))\n",
    "    return images_placeholder, labels_placeholder\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "            grads.append(expanded_g)\n",
    "        grad = tf.concat(grads, 0)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n",
    "\n",
    "def tower_loss(name_scope, logit, labels):\n",
    "    cross_entropy_mean = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logit) )\n",
    "    tf.summary.scalar(\n",
    "        name_scope + '_cross_entropy',\n",
    "        cross_entropy_mean)\n",
    "    \n",
    "    weight_decay_loss = tf.get_collection('weightdecay_losses')\n",
    "    tf.summary.scalar(name_scope + '_weight_decay_loss', tf.reduce_mean(weight_decay_loss) )\n",
    "\n",
    "  # Calculate the total loss for the current tower.\n",
    "    total_loss = cross_entropy_mean + weight_decay_loss \n",
    "    tf.summary.scalar(name_scope + '_total_loss', tf.reduce_mean(total_loss) )\n",
    "    return total_loss\n",
    "\n",
    "def tower_acc(logit, labels):\n",
    "    correct_pred = tf.equal(tf.argmax(logit, 1), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer)\n",
    "    return var\n",
    "\n",
    "def _variable_with_weight_decay(name, shape, wd):\n",
    "    var = _variable_on_cpu(name, shape, tf.contrib.layers.xavier_initializer())\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.nn.l2_loss(var)*wd\n",
    "        tf.add_to_collection('weightdecay_losses', weight_decay)\n",
    "    return var\n",
    "\n",
    "def run_training():\n",
    "  # Get the sets of images and labels for training, validation, and\n",
    "  # Tell TensorFlow that the model will be built into the default Graph.\n",
    "\n",
    "  # Create model directory\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    use_pretrained_model = True \n",
    "    model_filename = \"./sports1m_finetuning_ucf101.model\"\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        global_step = tf.get_variable(\n",
    "                    'global_step',\n",
    "                    [],\n",
    "                    initializer=tf.constant_initializer(0),\n",
    "                    trainable=False\n",
    "                    )\n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(\n",
    "                    FLAGS.batch_size * gpu_num\n",
    "                    )\n",
    "        tower_grads1 = []\n",
    "        tower_grads2 = []\n",
    "        logits = []\n",
    "        opt_stable = tf.train.AdamOptimizer(1e-4)\n",
    "        opt_finetuning = tf.train.AdamOptimizer(1e-3)\n",
    "        with tf.variable_scope('var_name') as var_scope:\n",
    "            weights = {\n",
    "              'wc1': _variable_with_weight_decay('wc1', [3, 3, 3, 3, 64], 0.0005),\n",
    "              'wc2': _variable_with_weight_decay('wc2', [3, 3, 3, 64, 128], 0.0005),\n",
    "              'wc3a': _variable_with_weight_decay('wc3a', [3, 3, 3, 128, 256], 0.0005),\n",
    "              'wc3b': _variable_with_weight_decay('wc3b', [3, 3, 3, 256, 256], 0.0005),\n",
    "              'wc4a': _variable_with_weight_decay('wc4a', [3, 3, 3, 256, 512], 0.0005),\n",
    "              'wc4b': _variable_with_weight_decay('wc4b', [3, 3, 3, 512, 512], 0.0005),\n",
    "              'wc5a': _variable_with_weight_decay('wc5a', [3, 3, 3, 512, 512], 0.0005),\n",
    "              'wc5b': _variable_with_weight_decay('wc5b', [3, 3, 3, 512, 512], 0.0005),\n",
    "              'wd1': _variable_with_weight_decay('wd1', [8192, 4096], 0.0005),\n",
    "              'wd2': _variable_with_weight_decay('wd2', [4096, 4096], 0.0005),\n",
    "              'out': _variable_with_weight_decay('wout', [4096, c3d_model.NUM_CLASSES], 0.0005)\n",
    "              }\n",
    "            biases = {\n",
    "              'bc1': _variable_with_weight_decay('bc1', [64], 0.000),\n",
    "              'bc2': _variable_with_weight_decay('bc2', [128], 0.000),\n",
    "              'bc3a': _variable_with_weight_decay('bc3a', [256], 0.000),\n",
    "              'bc3b': _variable_with_weight_decay('bc3b', [256], 0.000),\n",
    "              'bc4a': _variable_with_weight_decay('bc4a', [512], 0.000),\n",
    "              'bc4b': _variable_with_weight_decay('bc4b', [512], 0.000),\n",
    "              'bc5a': _variable_with_weight_decay('bc5a', [512], 0.000),\n",
    "              'bc5b': _variable_with_weight_decay('bc5b', [512], 0.000),\n",
    "              'bd1': _variable_with_weight_decay('bd1', [4096], 0.000),\n",
    "              'bd2': _variable_with_weight_decay('bd2', [4096], 0.000),\n",
    "              'out': _variable_with_weight_decay('bout', [c3d_model.NUM_CLASSES], 0.000),\n",
    "              }\n",
    "        for gpu_index in range(0, gpu_num):\n",
    "            with tf.device('/gpu:%d' % gpu_index):\n",
    "        \n",
    "                varlist2 = [ weights['out'],biases['out'] ]\n",
    "                varlist1 = list( set(weights.values() + biases.values()) - set(varlist2) )\n",
    "                logit = c3d_model.inference_c3d(\n",
    "                        images_placeholder[gpu_index * FLAGS.batch_size:(gpu_index + 1) * FLAGS.batch_size,:,:,:,:],\n",
    "                        0.5,\n",
    "                        FLAGS.batch_size,\n",
    "                        weights,\n",
    "                        biases\n",
    "                        )\n",
    "                loss_name_scope = ('gpud_%d_loss' % gpu_index)\n",
    "                loss = tower_loss(\n",
    "                        loss_name_scope,\n",
    "                        logit,\n",
    "                        labels_placeholder[gpu_index * FLAGS.batch_size:(gpu_index + 1) * FLAGS.batch_size]\n",
    "                        )\n",
    "                grads1 = opt_stable.compute_gradients(loss, varlist1)\n",
    "                grads2 = opt_finetuning.compute_gradients(loss, varlist2)\n",
    "                tower_grads1.append(grads1)\n",
    "                tower_grads2.append(grads2)\n",
    "                logits.append(logit)\n",
    "        logits = tf.concat(logits,0)\n",
    "        accuracy = tower_acc(logits, labels_placeholder)\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "        grads1 = average_gradients(tower_grads1)\n",
    "        grads2 = average_gradients(tower_grads2)\n",
    "        apply_gradient_op1 = opt_stable.apply_gradients(grads1)\n",
    "        apply_gradient_op2 = opt_finetuning.apply_gradients(grads2, global_step=global_step)\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "        variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "        train_op = tf.group(apply_gradient_op1, apply_gradient_op2, variables_averages_op)\n",
    "        null_op = tf.no_op()\n",
    "\n",
    "    # Create a saver for writing training checkpoints.\n",
    "        saver = tf.train.Saver(weights.values() + biases.values())\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "    # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session(\n",
    "                    config=tf.ConfigProto(allow_soft_placement=True)\n",
    "                    )\n",
    "        sess.run(init)\n",
    "        if os.path.isfile(model_filename) and use_pretrained_model:\n",
    "            saver.restore(sess, model_filename)\n",
    "\n",
    "    # Create summary writter\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('./visual_logs/train', sess.graph)\n",
    "        test_writer = tf.summary.FileWriter('./visual_logs/test', sess.graph)\n",
    "        for step in xrange(FLAGS.max_steps):\n",
    "            start_time = time.time()\n",
    "            train_images, train_labels, _, _, _ = input_data.read_clip_and_label(\n",
    "                      filename='list/train.list',\n",
    "                      batch_size=FLAGS.batch_size * gpu_num,\n",
    "                      num_frames_per_clip=c3d_model.NUM_FRAMES_PER_CLIP,\n",
    "                      crop_size=c3d_model.CROP_SIZE,\n",
    "                      shuffle=True\n",
    "                      )\n",
    "        sess.run(train_op, feed_dict={\n",
    "                      images_placeholder: train_images,\n",
    "                      labels_placeholder: train_labels\n",
    "                      })\n",
    "        duration = time.time() - start_time\n",
    "        print('Step %d: %.3f sec' % (step, duration))\n",
    "\n",
    "      # Save a checkpoint and evaluate the model periodically.\n",
    "        if (step) % 10 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "            saver.save(sess, os.path.join(model_save_dir, 'c3d_ucf_model'), global_step=step)\n",
    "            print('Training Data Eval:')\n",
    "            summary, acc = sess.run(\n",
    "                        [merged, accuracy],\n",
    "                        feed_dict={images_placeholder: train_images,\n",
    "                            labels_placeholder: train_labels\n",
    "                            })\n",
    "            print (\"accuracy: \" + \"{:.5f}\".format(acc))\n",
    "            train_writer.add_summary(summary, step)\n",
    "            print('Validation Data Eval:')\n",
    "            val_images, val_labels, _, _, _ = input_data.read_clip_and_label(\n",
    "                        filename='list/test.list',\n",
    "                        batch_size=FLAGS.batch_size * gpu_num,\n",
    "                        num_frames_per_clip=c3d_model.NUM_FRAMES_PER_CLIP,\n",
    "                        crop_size=c3d_model.CROP_SIZE,\n",
    "                        shuffle=True\n",
    "                        )\n",
    "            summary, acc = sess.run(\n",
    "                        [merged, accuracy],\n",
    "                        feed_dict={\n",
    "                                        images_placeholder: val_images,\n",
    "                                        labels_placeholder: val_labels\n",
    "                                        })\n",
    "            print (\"accuracy: \" + \"{:.5f}\".format(acc))\n",
    "            test_writer.add_summary(summary, step)\n",
    "    print(\"done\")\n",
    "\n",
    "def main(_):\n",
    "    run_training()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
